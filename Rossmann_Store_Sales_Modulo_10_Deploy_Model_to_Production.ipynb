{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ricardojnf33/Rossmann_Store_Sales/blob/main/Rossmann_Store_Sales_Modulo_10_Deploy_Model_to_Production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cme0l2fgyTFh"
      },
      "source": [
        "# 0.0. IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htMUGdWbyTFd",
        "outputId": "736c69cd-f5c3-4e11-fc44-a1e38365c7b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting inflection\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Collecting boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython) (0.2.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->boruta) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->boruta) (3.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython) (0.7.0)\n",
            "Installing collected packages: inflection, boruta\n",
            "Successfully installed boruta-0.3 inflection-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install inflection seaborn matplotlib IPython boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVnPHVB0yTFj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import random\n",
        "import pickle\n",
        "import warnings\n",
        "import inflection\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "\n",
        "from matplotlib            import pyplot as plt\n",
        "from IPython.core.display  import HTML\n",
        "from IPython.display       import Image\n",
        "from scipy                 import stats  as ss\n",
        "from boruta                import BorutaPy\n",
        "from random                import sample\n",
        "from flask import Flask, request, Response\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble      import RandomForestRegressor\n",
        "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model  import LinearRegression, Lasso\n",
        "\n",
        "warnings.filterwarnings( 'ignore' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q6NwTF7yTFj"
      },
      "source": [
        "## 0.1. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvgMZOoeyTFk"
      },
      "outputs": [],
      "source": [
        "def cross_validation( x_training, kfold, model_name, model, verbose=False ):\n",
        "    mae_list = []\n",
        "    mape_list = []\n",
        "    rmse_list = []\n",
        "    for k in reversed( range( 1, kfold+1 ) ):\n",
        "        if verbose:\n",
        "            print( '\\nKFold Number: {}'.format( k ) )\n",
        "        # \"start and end\" date for validation\n",
        "        validation_start_date = x_training['date'].max() - datetime.timedelta( days=k*6*7 )\n",
        "        validation_end_date = x_training['date'].max() - datetime.timedelta( days=(k-1)*6*7 )\n",
        "\n",
        "        # filtering dataset\n",
        "        training = x_training[x_training['date'] < validation_start_date]\n",
        "        validation = x_training[(x_training['date'] >= validation_start_date) & (x_training['date'] <= validation_end_date ) ]\n",
        "\n",
        "        # training and validation dataset\n",
        "        # training\n",
        "        xtraining = training.drop( ['date', 'sales'], axis=1 )\n",
        "        ytraining = training['sales']\n",
        "\n",
        "        # validation\n",
        "        xvalidation = validation.drop( ['date', 'sales'], axis=1 )\n",
        "        yvalidation = validation['sales']\n",
        "\n",
        "        # model\n",
        "        m = model.fit( xtraining, ytraining )\n",
        "\n",
        "        # prediction\n",
        "        yhat = m.predict( xvalidation )\n",
        "\n",
        "        # performance\n",
        "        m_result = ml_error( model_name, np.expm1( yvalidation ), np.expm1( yhat ) )\n",
        "\n",
        "        # store performance of each kfold iteration\n",
        "        mae_list.append( m_result[ 'MAE' ] )\n",
        "        mape_list.append( m_result[ 'MAPE' ] )\n",
        "        rmse_list.append( m_result[ 'RMSE' ] )\n",
        "\n",
        "    return pd.DataFrame( { 'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype ( str ),\n",
        "                        'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype ( str ),\n",
        "                        'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype ( str ) }, index=[0] )\n",
        "\n",
        "def mean_absolute_percentage_error( y, yhat ):\n",
        "    return np.mean( np.abs( ( y - yhat ) / y)  )\n",
        "\n",
        "\n",
        "def ml_error( model_name, y, yhat ):\n",
        "    mae = mean_absolute_error( y, yhat )\n",
        "    mape = mean_absolute_percentage_error( y, yhat )\n",
        "    rmse = np.sqrt( mean_squared_error( y, yhat ) )\n",
        "\n",
        "    return pd.DataFrame ( { 'Model Name': model_name,\n",
        "                            'MAE': mae,\n",
        "                            'MAPE': mape,\n",
        "                            'RMSE': rmse }, index=[0] ) \n",
        "\n",
        "def cramer_v( x, y ) :\n",
        "    cm = pd.crosstab( x, y ).values    \n",
        "    n = cm.sum()\n",
        "    r, k = cm.shape\n",
        "\n",
        "    chi2 = ss.chi2_contingency( cm )[0]\n",
        "    \n",
        "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) ) #Correção do Bias\n",
        "    kcorr = k - (k-1)**2/(n-1)\n",
        "    rcorr = r - (r-1)**2/(n-1)\n",
        "\n",
        "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1,rcorr-1 ) ) )\n",
        "\n",
        "def jupyter_settings():\n",
        "    %matplotlib inline\n",
        "    %pylab inline\n",
        "    \n",
        "    plt.style.use( 'bmh' )\n",
        "    plt.rcParams['figure.figsize'] = [25, 12]\n",
        "    plt.rcParams['font.size'] = 24\n",
        "    \n",
        "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
        "    pd.options.display.max_columns = None\n",
        "    pd.options.display.max_rows = None\n",
        "    pd.set_option( 'display.expand_frame_repr', False )\n",
        "    \n",
        "    sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8h8HoeqyTFl",
        "outputId": "d5ae4ff7-1975-4142-dfe7-f77544e24d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "jupyter_settings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY-VPfJC7sls",
        "outputId": "0f8938cf-39cd-445a-c1a9-de075df1b3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Rossmann_Store_Sales'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 110 (delta 58), reused 31 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 17.71 MiB | 8.81 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ricardojnf33/Rossmann_Store_Sales.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evMVehWtyTFl"
      },
      "source": [
        "## 0.2. Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOS2CyzJyTFm"
      },
      "outputs": [],
      "source": [
        "df_sales_raw = pd.read_csv( '/content/Rossmann_Store_Sales/Dataset/train.csv', low_memory=False )\n",
        "df_store_raw = pd.read_csv( '/content/Rossmann_Store_Sales/Dataset/test.csv', low_memory=False )\n",
        "\n",
        "# merge\n",
        "df_raw = pd.merge( df_sales_raw, df_store_raw, how='left', on='Store' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAFJ7tGZyTFn"
      },
      "source": [
        "# 1.0. PASSO 01 - DESCRICAO DOS DADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQW4OupGyTFn"
      },
      "outputs": [],
      "source": [
        "df1 = df_raw.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEPkhdtxyTFo"
      },
      "source": [
        "## 1.1. Rename Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwozLdtfyTFo"
      },
      "outputs": [],
      "source": [
        "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
        "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
        "            'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
        "\n",
        "snakecase = lambda x: inflection.underscore( x )\n",
        "\n",
        "cols_new = list( map( snakecase, cols_old ) )\n",
        "\n",
        "# rename\n",
        "df1.columns = cols_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU_NLcbfyTFo"
      },
      "source": [
        "## 1.2. Data Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg1Qv8E0yTFp"
      },
      "outputs": [],
      "source": [
        "print( 'Number of Rows: {}'.format( df1.shape[0] ) )\n",
        "print( 'Number of Cols: {}'.format( df1.shape[1] ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFO6TERpyTFp"
      },
      "source": [
        "## 1.3. Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DkoKZMyTFp"
      },
      "outputs": [],
      "source": [
        "df1['date'] = pd.to_datetime( df1['date'] )\n",
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVDL2bzyTFp"
      },
      "source": [
        "## 1.4. Check NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImK_JqfzyTFq"
      },
      "outputs": [],
      "source": [
        "df1.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVc5kcYLyTFq"
      },
      "source": [
        "## 1.5. Fillout NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WPMXWkFyTFq"
      },
      "outputs": [],
      "source": [
        "df1.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkU2I4_zyTFq"
      },
      "outputs": [],
      "source": [
        "#competition_distance        \n",
        "df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
        "\n",
        "#competition_open_since_month\n",
        "df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
        "\n",
        "#competition_open_since_year \n",
        "df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
        "\n",
        "#promo2_since_week           \n",
        "df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
        "\n",
        "#promo2_since_year           \n",
        "df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
        "\n",
        "#promo_interval              \n",
        "month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
        "\n",
        "df1['promo_interval'].fillna(0, inplace=True )\n",
        "\n",
        "df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
        "\n",
        "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bh5p1YHyTFr"
      },
      "outputs": [],
      "source": [
        "df1.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jyu4OryTFr"
      },
      "source": [
        "## 1.6. Change Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glXRA3LFyTFr"
      },
      "outputs": [],
      "source": [
        "# competiton\n",
        "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
        "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
        "    \n",
        "# promo2\n",
        "df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
        "df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88-Rbd55yTFr"
      },
      "source": [
        "## 1.7. Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiN_isnYyTFs"
      },
      "outputs": [],
      "source": [
        "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )\n",
        "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFVOirKVyTFs"
      },
      "source": [
        "### 1.7.1. Numerical Atributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYh7AEClyTFs"
      },
      "outputs": [],
      "source": [
        "# Central Tendency - mean, meadina \n",
        "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
        "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
        "\n",
        "# dispersion - std, min, max, range, skew, kurtosis\n",
        "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T \n",
        "d2 = pd.DataFrame( num_attributes.apply( min ) ).T \n",
        "d3 = pd.DataFrame( num_attributes.apply( max ) ).T \n",
        "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T \n",
        "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T \n",
        "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T \n",
        "\n",
        "# concatenar\n",
        "m = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
        "m.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDIPsy2XyTFt"
      },
      "outputs": [],
      "source": [
        "sns.distplot( df1['competition_distance'], kde=False )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JFuaY1VyTFt"
      },
      "source": [
        "### 1.7.2. Categorical Atributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwPcToYdyTFt"
      },
      "outputs": [],
      "source": [
        "cat_attributes.apply( lambda x: x.unique().shape[0] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66_eZK4dyTFt"
      },
      "outputs": [],
      "source": [
        "aux = df1[(df1['state_holiday'] != '0') & (df1['sales'] > 0)]\n",
        "\n",
        "plt.subplot( 1, 3, 1 )\n",
        "sns.boxplot( x='state_holiday', y='sales', data=aux )\n",
        "\n",
        "plt.subplot( 1, 3, 2 )\n",
        "sns.boxplot( x='store_type', y='sales', data=aux )\n",
        "\n",
        "plt.subplot( 1, 3, 3 )\n",
        "sns.boxplot( x='assortment', y='sales', data=aux )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS8hzOB4yTFu"
      },
      "source": [
        "# 2.0. PASSO 02 - FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdA7CVhQyTFu"
      },
      "outputs": [],
      "source": [
        "df2 = df1.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO2hs5lcyTFu"
      },
      "source": [
        "## 2.1. Mapa Mental de Hipoteses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yl27TDD6yTFu"
      },
      "outputs": [],
      "source": [
        "Image( '/content/Rossmann_Store_Sales/MindMapHypothesis.png' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niSe3joDyTFu"
      },
      "source": [
        "## 2.2. Criacao das Hipoteses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CRBfVeJyTFu"
      },
      "source": [
        "### 2.2.1. Hipoteses Loja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNkczX2nyTFv"
      },
      "source": [
        "**1.** Lojas com número maior de funcionários deveriam vender mais.\n",
        "\n",
        "**2.** Lojas com maior capacidade de estoque deveriam vender mais.\n",
        "\n",
        "**3.** Lojas com maior porte deveriam vender mais.\n",
        "\n",
        "**4.** Lojas com maior sortimentos deveriam vender mais.\n",
        "\n",
        "**5.** Lojas com competidores mais próximos deveriam vender menos.\n",
        "\n",
        "**6.** Lojas com competidores à mais tempo deveriam vendem mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga_QMYZuyTFv"
      },
      "source": [
        "### 2.2.2. Hipoteses Produto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWhvPgFRyTFv"
      },
      "source": [
        "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
        "\n",
        "**2.** Lojas com maior exposição de produto deveriam vender mais.\n",
        "\n",
        "**3.** Lojas com produtos com preço menor deveriam vender mais.\n",
        "\n",
        "**5.** Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
        "\n",
        "**6.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
        "\n",
        "**7.** Lojas com mais dias de promoção deveriam vender mais.\n",
        "\n",
        "**8.** Lojas com mais promoções consecutivas deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWqG1AYJyTFv"
      },
      "source": [
        "### 2.2.3. Hipoteses Tempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SMbaJRxyTFv"
      },
      "source": [
        "**1.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
        "\n",
        "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
        "\n",
        "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
        "\n",
        "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
        "\n",
        "**5.** Lojas deveriam vender menos aos finais de semana.\n",
        "\n",
        "**6.** Lojas deveriam vender menos durante os feriados escolares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUeCXTpyyTFv"
      },
      "source": [
        "## 2.3. Lista Final de Hipóteses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr2zDGaXyTFv"
      },
      "source": [
        "**1.** Lojas com maior sortimentos deveriam vender mais.\n",
        "\n",
        "**2.** Lojas com competidores mais próximos deveriam vender menos.\n",
        "\n",
        "**3.** Lojas com competidores à mais tempo deveriam vendem mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITkuXSN6yTFw"
      },
      "source": [
        "**4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
        "\n",
        "**5.** Lojas com mais dias de promoção deveriam vender mais.\n",
        "\n",
        "**7.** Lojas com mais promoções consecutivas deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUFM4-o_yTFw"
      },
      "source": [
        "**8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
        "\n",
        "**9.** Lojas deveriam vender mais ao longo dos anos.\n",
        "\n",
        "**10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
        "\n",
        "**11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
        "\n",
        "**12.** Lojas deveriam vender menos aos finais de semana.\n",
        "\n",
        "**13.** Lojas deveriam vender menos durante os feriados escolares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRiWMOiSyTFw"
      },
      "source": [
        "## 2.4. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBAhO8wiyTFw"
      },
      "outputs": [],
      "source": [
        "# year\n",
        "df2['year'] = df2['date'].dt.year\n",
        "\n",
        "# month\n",
        "df2['month'] = df2['date'].dt.month\n",
        "\n",
        "# day\n",
        "df2['day'] = df2['date'].dt.day\n",
        "\n",
        "# week of year\n",
        "df2['week_of_year'] = df2['date'].dt.isocalendar().week \n",
        "\n",
        "# year week\n",
        "df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
        "\n",
        "# competition since\n",
        "df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
        "df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
        "\n",
        "# promo since\n",
        "df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
        "df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
        "df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
        "\n",
        "# assortment\n",
        "df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
        "\n",
        "# state holiday\n",
        "df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DtHBNRayTFw"
      },
      "source": [
        "# 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1YRpxvOyTFw"
      },
      "outputs": [],
      "source": [
        "df3 = df2.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLq21TCyTFw"
      },
      "source": [
        "## 3.1. Filtragem das Linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIywU82fyTFw"
      },
      "outputs": [],
      "source": [
        "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mfk5KzKyTFx"
      },
      "source": [
        "## 3.2. Selecao das Colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rudz-7njyTFx"
      },
      "outputs": [],
      "source": [
        "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
        "df3 = df3.drop( cols_drop, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU19P0jvyTFx"
      },
      "outputs": [],
      "source": [
        "df3.head().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVgxFl_oml9b"
      },
      "source": [
        "# 4.0. PASSO 04 - ANALISE EXPLORATORIA DE DADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl5BtNwmyTFx"
      },
      "outputs": [],
      "source": [
        "df4 = df3.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFlchIns1FE"
      },
      "source": [
        "## 4.1. ANALISE UNIVARIADA ( Olhar únicamente para cada variável )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4XkvK0TtN6y"
      },
      "source": [
        "### 4.1.1. Response Variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1pArXNstqOK"
      },
      "outputs": [],
      "source": [
        "sns.displot( df4['sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v-ofk6DtXwk"
      },
      "source": [
        "### 4.1.2. Numerical Variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X1rB_DJuDtQ"
      },
      "outputs": [],
      "source": [
        "num_attributes.hist( bins=25 );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMdKWQI_tgFv"
      },
      "source": [
        "### 4.1.3. Categorical Variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8anT5Qcu7i7"
      },
      "outputs": [],
      "source": [
        "df4['store_type'].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wuUpcS8v67M"
      },
      "outputs": [],
      "source": [
        "# state_holiday\n",
        "plt.subplot( 3, 2, 1 )\n",
        "a = df4[df4['state_holiday'] != 'regular_day']\n",
        "sns.countplot( a['state_holiday'] )\n",
        "\n",
        "plt.subplot( 3, 2, 2 )\n",
        "sns.kdeplot( df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True )\n",
        "sns.kdeplot( df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True )\n",
        "sns.kdeplot( df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True )\n",
        "\n",
        "#store_type\n",
        "plt.subplot( 3, 2, 3 )\n",
        "sns.countplot( df4['store_type'] )\n",
        "\n",
        "plt.subplot( 3, 2, 4 )\n",
        "sns.kdeplot( df4[df4['store_type'] == 'a']['sales'], label='a', shade=True )\n",
        "sns.kdeplot( df4[df4['store_type'] == 'b']['sales'], label='b', shade=True )\n",
        "sns.kdeplot( df4[df4['store_type'] == 'c']['sales'], label='c', shade=True )\n",
        "sns.kdeplot( df4[df4['store_type'] == 'd']['sales'], label='d', shade=True )\n",
        "\n",
        "#assortment\n",
        "plt.subplot( 3, 2, 5 )\n",
        "sns.countplot( df4['assortment'] )\n",
        "\n",
        "plt.subplot( 3, 2, 6 )\n",
        "sns.kdeplot( df4[df4['assortment'] == 'extended']['sales'], label='extended', shade=True )\n",
        "sns.kdeplot( df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True )\n",
        "sns.kdeplot( df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True )\n",
        "sns.kdeplot( df4[df4['assortment'] == 'd']['sales'], label='d', shade=True )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIIAH779s09U"
      },
      "source": [
        "## 4.2. ANALISE BIVARIADA ( Encontrar o impacto de uma variável em relação a variável resposta )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osb6FsCT_rhM"
      },
      "source": [
        "### H1. Lojas com maior sortimentos deveriam vender mais.\n",
        "### ***FALSA*** Lojas com maior sortimento vendem menos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wItUxTEoAPSJ"
      },
      "outputs": [],
      "source": [
        "#Quantidade de venda por tipo de assortment\n",
        "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index() \n",
        "sns.barplot( x='assortment', y='sales', data=aux1 );\n",
        "\n",
        "aux2 = df4[[ 'year_week', 'assortment', 'sales']].groupby( ['year_week','assortment'] ).sum().reset_index()\n",
        "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
        "\n",
        "aux3 = aux2[aux2['assortment'] == 'extra' ]\n",
        "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFMt96V3bSVO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqHndotYAGNi"
      },
      "source": [
        "### H2. Lojas com competidores mais próximos deveriam vender menos.\n",
        "### ***FALSA*** Lojas com COMPETIDORES MAIS PROXIMOS vendem MAIS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX4clqzfZvSR"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'figure.figsize':(30,15), 'figure.dpi':100})\n",
        "\n",
        "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 1, 3, 1 )\n",
        "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 1, 3, 2 )\n",
        "bins = list( np.arange( 0, 20000, 1000 ) )\n",
        "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
        "aux2 = aux1[['competition_distance_binned', 'sales']].groupby( 'competition_distance_binned' ).sum().reset_index()\n",
        "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
        "plt.xticks( rotation=90 );\n",
        "\n",
        "plt.subplot( 1, 3, 3 )\n",
        "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3utuDePAGKc"
      },
      "source": [
        "### H3. Lojas com competidores à mais tempo deveriam vender mais.\n",
        "### ***FALSA*** Lojas com COMPETIDORES À MAIS TEMPO vendem MENOS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6beFHb_LdVk"
      },
      "outputs": [],
      "source": [
        "plt.subplot(  1, 3, 1 )\n",
        "aux1 = df4[['competition_time_month', 'sales']].groupby( 'competition_time_month' ).sum().reset_index()\n",
        "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & ( aux1['competition_time_month'] != 0 )]\n",
        "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
        "plt.xticks( rotation=90 );\n",
        "\n",
        "plt.subplot(  1, 3, 2 )\n",
        "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
        "\n",
        "plt.subplot(  1, 3, 3 )\n",
        "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );\n",
        "bottom, top = x.get_ylim()\n",
        "x.set_ylim( bottom+0.5, top-0.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBmEtrqlAGHk"
      },
      "source": [
        "### H4. Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
        "### ***FALSA*** Lojas com promoções ativas por mais tempo, vendem menos depois de um certo período de promoção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O40Ntj1-Vkhm"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
        "\n",
        "grid = GridSpec( 2, 3 )\n",
        "\n",
        "plt.subplot( grid[0,0] )\n",
        "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendida\n",
        "sns.barplot( x='promo_time_week' , y='sales', data=aux2 );\n",
        "plt.xticks( rotation=90 );\n",
        "\n",
        "plt.subplot( grid[0,1] )\n",
        "sns.regplot( x='promo_time_week' , y='sales', data=aux2 );\n",
        "\n",
        "plt.subplot( grid[1,0] )\n",
        "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
        "sns.barplot( x='promo_time_week' , y='sales', data=aux3 );\n",
        "plt.xticks( rotation=90 );\n",
        "\n",
        "plt.subplot( grid[1,1] )\n",
        "sns.regplot( x='promo_time_week' , y='sales', data=aux3 );\n",
        "\n",
        "plt.subplot( grid[:,2] )\n",
        "sns.heatmap( aux1.corr(method='pearson' ), annot=True );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGHeenp1AGEk"
      },
      "source": [
        "### H5. Lojas com mais dias de promoção deveriam vender mais. #Validar no próximo ciclo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wcb63r9AGB2"
      },
      "source": [
        "### H7. Lojas com mais promoções consecutivas deveriam vender mais.\n",
        "### ***FALSA*** Lojas com mais promoções consecutivas vendem menos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cqAbNaO4Zgt"
      },
      "outputs": [],
      "source": [
        "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2' ] ).sum().reset_index() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDzA9-v55XvY"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week','sales']].groupby( 'year_week' ).sum().reset_index()\n",
        "ax = aux1.plot()\n",
        "\n",
        "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week','sales']].groupby( 'year_week' ).sum().reset_index()\n",
        "aux2.plot( ax=ax )\n",
        "\n",
        "ax.legend( labels=['Tradicional & Extendida', 'Extendida']);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV3e7IBfAF7i"
      },
      "source": [
        "### H8. Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
        "### ***FALSA*** Lojas abertas durante o feriado do natal vendem menos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyndMXeot9vI"
      },
      "outputs": [],
      "source": [
        "aux = df4[df4['state_holiday'] != 'regular_day']\n",
        "\n",
        "plt.subplot( 1, 2, 1 )\n",
        "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
        "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 1, 2, 2 )\n",
        "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year', 'state_holiday'] ).sum().reset_index()\n",
        "sns.barplot( x='year' , y='sales', hue='state_holiday', data=aux2 );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7f6Pby9AF0J"
      },
      "source": [
        "### H9. Lojas deveriam vender mais ao longo dos anos.\n",
        "### ***FALSA*** Lojas vendem menos ao longo dos anos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlAxsRNFVHQR"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 1, 3, 1 )\n",
        "sns.barplot( x='year', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 1, 3, 2 )\n",
        "sns.regplot( x='year', y='sales', data=aux1 ); #Gráfico de tendêcia\n",
        "\n",
        "plt.subplot( 1, 3, 3 )\n",
        "sns.heatmap( aux1.corr( method='pearson' ), annot=True ); #Gráfico de correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKaGxcjgAF-2"
      },
      "source": [
        "### H10. Lojas deveriam vender mais no segundo semestre do ano.\n",
        "### ***FALSA*** Lojas vendem menos no segundo semestre do ano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J7WLcOHZC8f"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 1, 3, 1 )\n",
        "sns.barplot( x='month', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 1, 3, 2 )\n",
        "sns.regplot( x='month', y='sales', data=aux1 ); #Gráfico de tendêcia\n",
        "\n",
        "plt.subplot( 1, 3, 3 )\n",
        "sns.heatmap( aux1.corr( method='pearson' ), annot=True ); #Gráfico de correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhreIpfEtfjf"
      },
      "source": [
        "### H11. Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
        "### ***VERDADEIRA*** Lojas vendem menos no segundo semestre do ano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAmzvJGIZYb0"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 2, 2, 1 )\n",
        "sns.barplot( x='day', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 2, 2, 2 )\n",
        "sns.regplot( x='day', y='sales', data=aux1 ); #Gráfico de tendêcia\n",
        "\n",
        "plt.subplot( 2, 2, 3 )\n",
        "sns.heatmap( aux1.corr( method='pearson' ), annot=True ); #Gráfico de correlação\n",
        "\n",
        "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
        "aux2 = aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 2, 2, 4 )\n",
        "sns.barplot( x='before_after', y='sales', data=aux2 );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDBxiOfztfWc"
      },
      "source": [
        "### H12. Lojas deveriam vender menos aos finais de semana.\n",
        "### ***VERDADEIRA*** Lojas vendem menos nos finais de semana."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q45rLpvmb7S-"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 1, 3, 1 )\n",
        "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 1, 3, 2 )\n",
        "sns.regplot( x='day_of_week', y='sales', data=aux1 ); #Gráfico de tendêcia\n",
        "\n",
        "plt.subplot( 1, 3, 3 )\n",
        "sns.heatmap( aux1.corr( method='pearson' ), annot=True ); #Gráfico de correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4hPY7gWt3qV"
      },
      "source": [
        "### H13. Lojas deveriam vender menos durante os feriados escolares.\n",
        "### ***VERDADEIRA*** Lojas vendem menos durante os feriados escolares, exceto os meses de julho e agosto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viio8dRbdGsd"
      },
      "outputs": [],
      "source": [
        "aux1 = df4[[ 'school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
        "\n",
        "plt.subplot( 2, 1, 1 )\n",
        "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
        "\n",
        "plt.subplot( 2, 1, 2 )\n",
        "aux2 = df4[['month', 'school_holiday', 'sales']].groupby( ['month','school_holiday'] ).sum().reset_index()\n",
        "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Sqpjqknpz-"
      },
      "source": [
        "## 4.2.1. Resumo das hipóteses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ePSJ9DEn4zn"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVlLf0VMoBVV"
      },
      "outputs": [],
      "source": [
        "tab=[[' Hipoteses', 'Conclusao', 'Relevancia'],\n",
        "     ['H1', 'Falsa', 'Baixa'],\n",
        "     ['H2', 'Falsa', 'Media'],\n",
        "     ['H3', 'Falsa', 'Media'],\n",
        "     ['H4', 'Falsa', 'Baixa'],\n",
        "     ['H5', '_', '_'],\n",
        "     ['H7', 'Falsa', 'Baixa'],\n",
        "     ['H8', 'Falsa', 'Media'],\n",
        "     ['H9', 'Falsa', 'Alta'],\n",
        "     ['H10', 'Falsa', 'Alta'],\n",
        "     ['H11', 'Verdadeira', 'Alta'],\n",
        "     ['H12', 'Verdadeira', 'Alta'],\n",
        "     ['H13', 'Verdadeira', 'Baixa'],\n",
        "    ]\n",
        "print( tabulate( tab, headers='firstrow' ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHR4BxhwszJZ"
      },
      "source": [
        "## 4.3. ANALISE MULTIVARIADA  ( Encontrar as correlações entre as próprias variáveis )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-cSDG6wt02R"
      },
      "source": [
        "### 4.3.1 Numerical Attributes ( Variáveis numéricas -> método de Pearson )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d9SEhe-xh-g"
      },
      "outputs": [],
      "source": [
        "correlation = num_attributes.corr( method='pearson' )\n",
        "sns.heatmap( correlation, annot=True );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BS4fErVt_mO"
      },
      "source": [
        "### 4.3.1 Categorical Attributes ( Variáveis Categóricas -> método V de Cramer )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qff-2v2JyTFx"
      },
      "outputs": [],
      "source": [
        "# only categorical data\n",
        "a = df4.select_dtypes( include='object' )\n",
        "\n",
        "# Calculate cramer V\n",
        "a1 = cramer_v(a['state_holiday'], a['state_holiday'] ) \n",
        "a2 = cramer_v(a['state_holiday'], a['store_type'] ) \n",
        "a3 = cramer_v(a['state_holiday'], a['assortment'] )\n",
        "\n",
        "a4 = cramer_v(a['store_type'], a['state_holiday'] )\n",
        "a5 = cramer_v(a['store_type'], a['store_type'] )\n",
        "a6 = cramer_v(a['store_type'], a['assortment'] )\n",
        "\n",
        "a7 = cramer_v(a['assortment'], a['state_holiday'] )\n",
        "a8 = cramer_v(a['assortment'], a['store_type'] )\n",
        "a9 = cramer_v(a['assortment'], a['assortment'] )\n",
        "\n",
        "# Final dataset\n",
        "d = pd.DataFrame( {'state_holiday': [a1, a2, a3], \n",
        "               'store_type': [a4, a5, a6], \n",
        "               'assortment': [a7, a8, a9] })\n",
        "\n",
        "d = d.set_index( d.columns )\n",
        "\n",
        "sns.heatmap( d, annot=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoBuvjNi_t0_"
      },
      "source": [
        "# 5.0. PASSO 05 - DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTYxI2vSCYJ2"
      },
      "outputs": [],
      "source": [
        "df5 = df4.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHvp6W8oCfP-"
      },
      "source": [
        "## 5.1. Normalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvKvzhu8CeAC"
      },
      "source": [
        "## 5.2. Rescaling ( Normalizando os ranges  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLdMEAOIF7Ke"
      },
      "outputs": [],
      "source": [
        "rs = RobustScaler() # Aplicado em variáveis com Outliers fortes\n",
        "mms = MinMaxScaler() # Aplicado em variáveis sem Outliers fortes\n",
        "\n",
        "# competition distance\n",
        "df5['competition_distance'] = rs.fit_transform( df5[['competition_distance']].values )\n",
        "pickle.dump( rs, open( '/content/competition_distance_scaler.pkl', 'wb') )\n",
        "files.download('/content/competition_distance_scaler.pkl')  \n",
        "# competition time month\n",
        "df5['competition_time_month'] = rs.fit_transform( df5[['competition_time_month']].values )\n",
        "pickle.dump( rs, open( '/content/competition_time_month_scaler.pkl','wb') )\n",
        "files.download('/content/competition_time_month_scaler.pkl') \n",
        "# promo time week\n",
        "df5['promo_time_week'] = mms.fit_transform( df5[['promo_time_week']].values )\n",
        "pickle.dump( rs, open( '/content/promo_time_week_scaler.pkl','wb') )\n",
        "files.download('/content/promo_time_week_scaler.pkl') \n",
        "# year\n",
        "df5['year'] = mms.fit_transform( df5[['year']].values )\n",
        "pickle.dump( mms, open( '/content/year_scaler.pkl','wb') )\n",
        "files.download('/content/year_scaler.pkl') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsUcwLrSpbmZ"
      },
      "outputs": [],
      "source": [
        "sns.displot( df5['competition_distance'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bvJiBgiCd9M"
      },
      "source": [
        "## 5.3. Transformação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpnBKG-YY0l"
      },
      "source": [
        "### 5.3.1. Enconding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0gUvkXVzOWa"
      },
      "outputs": [],
      "source": [
        "# state_holiday ( One Hot Enconding )\n",
        "df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
        "\n",
        "# store_type ( Label Encoding )\n",
        "le = LabelEncoder()\n",
        "df5['store_type'] = le.fit_transform( df5['store_type'] )\n",
        "pickle.dump( le, open( '/content/store_type_scaler.pkl','wb') )\n",
        "files.download('/content/store_type_scaler.pkl')\n",
        "\n",
        "# assortment ( Ordinal Encoding )\n",
        "assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
        "df5['assortment'] = df5['assortment'].map( assortment_dict )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m_ucl1t3ncQ"
      },
      "source": [
        "### 5.3.2. Response Variable Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQoB5IaC37f4"
      },
      "outputs": [],
      "source": [
        "df5['sales'] = np.log1p(df5['sales'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmwJE1zi4XwO"
      },
      "outputs": [],
      "source": [
        "sns.distplot( df5['sales'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJQ4NRCF8oJu"
      },
      "source": [
        "### 5.3.3. Nature Transformation ( Natureza Cíclica )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzlv5EkICsj_"
      },
      "outputs": [],
      "source": [
        "# month\n",
        "df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x* ( 2. * np.pi/12 ) ) )\n",
        "df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x* ( 2. * np.pi/12 ) ) )\n",
        "\n",
        "# day\n",
        "df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x* ( 2. * np.pi/30 ) ) )\n",
        "df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x* ( 2. * np.pi/30 ) ) )\n",
        "\n",
        "# week of year\n",
        "df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x* ( 2. * np.pi/52 ) ) )\n",
        "df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x* ( 2. * np.pi/52 ) ) )\n",
        "\n",
        "# day of week\n",
        "df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x* ( 2. * np.pi/7 ) ) )\n",
        "df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x* ( 2. * np.pi/7 ) ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYWDzDO1de7I"
      },
      "source": [
        "# 6.0. PASSO 06 - FEATURE SELECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJKYzui0-ZT-"
      },
      "outputs": [],
      "source": [
        "df6 = df5.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9cSWGlMdvMZ"
      },
      "source": [
        "## 6.1. Split dataframe into training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo0EBaHbedxt"
      },
      "outputs": [],
      "source": [
        "cols_drop = [ 'week_of_year', 'day', 'month', 'day_of_week', 'promo_since', 'competition_since', 'year_week' ]\n",
        "df6 = df6.drop( cols_drop, axis=1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch7yEAzGfF5z"
      },
      "outputs": [],
      "source": [
        "#df6[['store', 'date']].groupby( 'store' ).max().reset_index()['date'][0] - datetime.timedelta( days=6*7 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uKtftvLzygr"
      },
      "outputs": [],
      "source": [
        "# training dataset\n",
        "X_train = df6[df6['date'] < '2015-06-19' ]\n",
        "y_train = X_train['sales']\n",
        "\n",
        "# test dataset\n",
        "X_test = df6[df6['date'] >= '2015-06-19' ]\n",
        "y_test = X_test['sales']\n",
        "\n",
        "print( 'Training Min Date: {}'.format( X_train['date'].min() ) )\n",
        "print( 'Training Max Date: {}'.format( X_train['date'].max() ) )\n",
        "\n",
        "print( '\\nTest Min Date: {}'.format( X_test['date'].min() ) )\n",
        "print( 'Test Max Date: {}'.format( X_test['date'].max() ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R72pWFnyd9ZE"
      },
      "source": [
        "## 6.2. Boruta as Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1O1TBnzdtHf"
      },
      "outputs": [],
      "source": [
        "## training and test dataset for Boruta\n",
        "# X_train_n = X_train.drop( ['date', 'sales'], axis=1 ).values\n",
        "# y_train_n = y_train.values.ravel()\n",
        "\n",
        "## define RandomForestRegressor\n",
        "# rf = RandomForestRegressor( n_jobs=-1)\n",
        "\n",
        "## define Boruta\n",
        "# boruta = BorutaPy( rf, n_estimators='auto', verbose=2, random_state=42 ).fit( X_train_n, y_train_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezN_erKE7aOy"
      },
      "source": [
        "### 6.2.1. Best Features from Boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrk6lneg5dLU"
      },
      "outputs": [],
      "source": [
        "# cols_selected = boruta.support_.tolist()\n",
        "\n",
        "## best features\n",
        "# X_train_fs = X_train.drop( ['date', 'sales'], axis=1 )\n",
        "# cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
        "\n",
        "# not selected boruta\n",
        "# cols_not_selected_boruta = list( np.setdiff1d( X_train_fs.columns, cols_selected_boruta ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAUCjBXkpzKG"
      },
      "source": [
        "### 6.3. Manual Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFJlWwMlfH-W"
      },
      "outputs": [],
      "source": [
        "cols_selected_boruta = [\n",
        "    'store',\n",
        "    'promo',\n",
        "    'store_type',\n",
        "    'assortment',\n",
        "    'competition_distance',\n",
        "    'competition_open_since_month',\n",
        "    'competition_open_since_year',\n",
        "    'promo2',\n",
        "    'promo2_since_week',\n",
        "    'promo2_since_year',\n",
        "    'competition_time_month',\n",
        "    'promo_time_week',\n",
        "    'month_sin',\n",
        "    'month_cos',\n",
        "    'day_sin',\n",
        "    'day_cos',\n",
        "    'week_of_year_sin',\n",
        "    'week_of_year_cos',\n",
        "    'day_of_week_sin',\n",
        "    'day_of_week_cos']\n",
        "\n",
        "# columns to add\n",
        "feat_to_add = ['date', 'sales']\n",
        "\n",
        "# final features\n",
        "\n",
        "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
        "cols_selected_boruta_full.extend( feat_to_add )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6UAKnOlq_do"
      },
      "source": [
        "# 7.0. PASSO 07 - MACHINE LEARNING MODELING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8oHZ2NlVD9O"
      },
      "outputs": [],
      "source": [
        "x_train = X_train[ cols_selected_boruta ]\n",
        "x_test = X_test[ cols_selected_boruta ]\n",
        "\n",
        "# Time Series Data Preparation\n",
        "x_training = X_train[ cols_selected_boruta_full ] # todas as variáveis relevantes + date + sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ooXreuhUdQt"
      },
      "source": [
        "## 7.1. Average Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFlC1EXfNx8w"
      },
      "outputs": [],
      "source": [
        "aux1 = x_test.copy()\n",
        "aux1['sales'] = y_test.copy()\n",
        "\n",
        "# prediction\n",
        "aux2 = aux1[['store', 'sales']].groupby( 'store' ).mean().reset_index().rename( columns={'sales': 'predictions'} )\n",
        "aux1 = pd.merge( aux1, aux2, how='left', on='store' )\n",
        "yhat_baseline = aux1['predictions']\n",
        "\n",
        "# performance\n",
        "baseline_result = ml_error( 'Average Model', np.expm1( y_test ), np.expm1( yhat_baseline ) )\n",
        "baseline_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHqRjzSbUnGv"
      },
      "source": [
        "## 7.2. Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcNsrfGxNyA9"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "lr = LinearRegression().fit( x_train, y_train )\n",
        "\n",
        "# prediction\n",
        "yhat_lr = lr.predict( x_test )\n",
        "\n",
        "# performance\n",
        "lr_result = ml_error( 'Linear Regression', np.expm1( y_test ), np.expm1( yhat_lr ) )\n",
        "lr_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjw9QbM9UrnN"
      },
      "source": [
        "### 7.2.1. Linear Regression Model - Cross Validation\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mDeH6hzNx-v"
      },
      "outputs": [],
      "source": [
        "lr_result_cv = cross_validation( x_training, 5, 'Linear Regression', lr )\n",
        "lr_result_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epUmwLzMtGIg"
      },
      "source": [
        "## 7.3. Linear Regression Regularized Model - Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1U7Vow9Nx6f"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "lrr = Lasso( alpha=0.01 ).fit( x_train, y_train )\n",
        "\n",
        "# prediction\n",
        "yhat_lrr = lrr.predict( x_test )\n",
        "\n",
        "# performance\n",
        "lrr_result = ml_error( 'Linear Regression - Lasso', np.expm1( y_test ), np.expm1( yhat_lrr ) )\n",
        "lrr_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixnopyV9uQFg"
      },
      "source": [
        "### 7.3.1. Lasso - Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHL-AAemNx4V"
      },
      "outputs": [],
      "source": [
        "lrr_result_cv = cross_validation( x_training, 5, 'Lasso', lrr )\n",
        "lrr_result_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J95fe9-7y9S"
      },
      "source": [
        "## 7.4. Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3-mH7pXNx1f"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "rf = RandomForestRegressor( n_estimators=100, n_jobs=-1, random_state=42 ).fit( x_train, y_train )\n",
        "\n",
        "# prediction\n",
        "yhat_rf = rf.predict( x_test )\n",
        "\n",
        "# performance\n",
        "rf_result = ml_error( 'Random Forest Regressor', np.expm1( y_test ), np.expm1( yhat_rf ) )\n",
        "rf_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVO7wRBhIQ_"
      },
      "source": [
        "### 7.4.1. Random Forest Regressor Model - Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKmYTU-ahOKw"
      },
      "outputs": [],
      "source": [
        "rf_result_cv = cross_validation( x_training, 5, 'Random Forest Regressor', rf )\n",
        "rf_result_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOqFh1Bh83Nu"
      },
      "source": [
        "## 7.5. XGBoost Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zKDgWy0Nxzw"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
        "                              n_estimators=100,\n",
        "                              eta=0.01,\n",
        "                              max_depth=10,\n",
        "                              subsample=0.7,\n",
        "                              colsample_bytee=0.9 ).fit( x_train, y_train )\n",
        "\n",
        "# prediction\n",
        "yhat_xgb = model_xgb.predict( x_test )\n",
        "\n",
        "# performance\n",
        "xgb_result = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1( yhat_xgb ) )\n",
        "xgb_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWQ6OeleiIGk"
      },
      "source": [
        "### 7.5.1. XGBoost Regressor Model - Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rKJ-461iIfW"
      },
      "outputs": [],
      "source": [
        "xgb_result_cv = cross_validation( x_training, 5, 'XGBoost Regressor', model_xgb )\n",
        "xgb_result_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH95WOaTU6hu"
      },
      "source": [
        "## 7.6. Compare Model's Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y99H_AUAip9t"
      },
      "source": [
        "### 7.6.1. Single Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kN39OJMNxxb"
      },
      "outputs": [],
      "source": [
        "modelling_result = pd.concat( [baseline_result, lr_result, lrr_result, rf_result, xgb_result] )\n",
        "modelling_result.sort_values( 'RMSE' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcyWoDPiivm0"
      },
      "source": [
        "### 7.6.1. Real Performance - Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kub6MLyCis-8"
      },
      "outputs": [],
      "source": [
        "modelling_result_cv = pd.concat( [lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv] )\n",
        "modelling_result_cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l53P6u6ZDKUm"
      },
      "source": [
        "# 8.0. PASSO 08 - HYPERPARAMETER FINE TUNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2W5uJzrf7rX"
      },
      "source": [
        "## 8.1. Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXmBZi0Hg62a"
      },
      "outputs": [],
      "source": [
        "#param = {\n",
        "#    'n_estimators': [1500, 1700, 2500, 3000, 3500],\n",
        "#    'eta': [0.01, 0.03],\n",
        "#    'max_depth': [3, 5, 9],\n",
        "#    'subsample': [0.1, 0.5, 0.7],\n",
        "#    'colsample_bytee': [0.3, 0.7, 0.9],\n",
        "#    'min_child_weight': [3, 8, 15]\n",
        "#         }\n",
        "#MAX_EVAL = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FpGDfveDfGz"
      },
      "outputs": [],
      "source": [
        "#final_result = pd.DataFrame()\n",
        "\n",
        "#for i in range( MAX_EVAL ):\n",
        "#    # choose values for parameters randomly\n",
        "#    hp = { k: np.random.choice( v, 1 )[0] for k, v in param.items() }\n",
        "#    print( hp )\n",
        "\n",
        "#    # model\n",
        "#    model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
        "#                                n_estimators=hp['n_estimators'],\n",
        "#                                eta=hp['eta'],\n",
        "#                                max_depth=hp['max_depth'],\n",
        "#                                subsample=hp['subsample'],\n",
        "#                                colsample_bytee=hp['colsample_bytee'],\n",
        "#                                min_child_weight=hp['min_child_weight'] )\n",
        "    \n",
        "#    # performance\n",
        "#    result = cross_validation( x_training, 2, 'XGBoost Regressor', model_xgb, verbose=False )\n",
        "#    final_result = pd.concat( [final_result, result] )\n",
        "\n",
        "#final_result "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjQAZPoFgEf3"
      },
      "source": [
        "## 8.1. Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WuxsRJ4f3na"
      },
      "outputs": [],
      "source": [
        "param_tuned = {\n",
        "    'n_estimators': 3000,\n",
        "    'eta': 0.03,\n",
        "    'max_depth': 5,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytee': 0.7,\n",
        "    'min_child_weight': 3\n",
        "         }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWF5V_pxf3ko"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "model_xgb_tuned = xgb.XGBRegressor( objective='reg:squarederror',\n",
        "                                    n_estimators=param_tuned['n_estimators'],\n",
        "                                    eta=param_tuned['eta'],\n",
        "                                    max_depth=param_tuned['max_depth'],\n",
        "                                    subsample=param_tuned['subsample'],\n",
        "                                    colsample_bytee=param_tuned['colsample_bytee'],\n",
        "                                    min_child_weight=param_tuned['min_child_weight'] ).fit( x_train, y_train )\n",
        "\n",
        "# prediction\n",
        "yhat_xgb_tuned = model_xgb_tuned.predict( x_test )\n",
        "    \n",
        "# performance\n",
        "xgb_result_tuned = ml_error( 'XGBoost Regressor', np.expm1( y_test ), np.expm1( yhat_xgb_tuned ) )\n",
        "xgb_result_tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.3. Download do modelo final"
      ],
      "metadata": {
        "id": "Cc6QxrryIaUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.0. PASSO 09 - TRADUÇÃO E INTERPRETEÇÃO DO ERRO"
      ],
      "metadata": {
        "id": "lauhv_lWiWTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df9 = X_test[ cols_selected_boruta_full ]\n",
        "\n",
        "# rescale\n",
        "df9['sales'] = np.expm1( df9['sales'] )\n",
        "df9['predictions'] = np.expm1( yhat_xgb_tuned  )"
      ],
      "metadata": {
        "id": "XOCGT4aziiiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.1. Business Performance"
      ],
      "metadata": {
        "id": "iYbOmkZHilU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sum of predictions\n",
        "df91 = df9[['store', 'predictions']].groupby('store' ).sum().reset_index()\n",
        "\n",
        "# MAE and MAPE\n",
        "df9_aux1 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_error( x['sales'], x['predictions'] ) ).reset_index().rename(columns={0:'MAE'} )\n",
        "df9_aux2 = df9[['store', 'sales', 'predictions']].groupby( 'store' ).apply( lambda x: mean_absolute_percentage_error( x['sales'], x['predictions'] ) ).reset_index().rename(columns={0:'MAPE'} )\n",
        "\n",
        "# Merge\n",
        "df9_aux3 = pd.merge( df9_aux1, df9_aux2, how='inner', on='store' )\n",
        "df92 = pd.merge( df91, df9_aux3, how='inner', on='store' )\n",
        "\n",
        "# Scenarios\n",
        "df92['worst_scenario'] = df92['predictions'] - df92['MAE']\n",
        "df92['best_scenario'] = df92['predictions'] + df92['MAE']\n",
        "\n",
        "# order columns\n",
        "df92 = df92[[ 'store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE', 'MAPE']]"
      ],
      "metadata": {
        "id": "TjIUcE-4io81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df92.sample(10)"
      ],
      "metadata": {
        "id": "OU5FjhcmlPND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df92.sort_values( 'MAPE', ascending=False ).head()"
      ],
      "metadata": {
        "id": "Hot7B6ezoklL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot( x='store', y='MAPE', data=df92 )"
      ],
      "metadata": {
        "id": "3f6XXoT6o51F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.2. Total Performance"
      ],
      "metadata": {
        "id": "wKoboWOLipaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df93 = df92[['predictions', 'worst_scenario', 'best_scenario']].apply( lambda x: np.sum( x ), axis=0 ).reset_index().rename( columns={'index': 'Scenario', 0: 'Values'} )\n",
        "df93['Values'] = df93['Values'].map( 'R${:,.2f}'.format )\n",
        "df93"
      ],
      "metadata": {
        "id": "C170HJKaitqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.3. Machine Learning Performance"
      ],
      "metadata": {
        "id": "lxvl9H17iuMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df9['error'] = df9['sales'] - df9['predictions']\n",
        "df9['error_rate'] = df9['predictions'] / df9['sales']"
      ],
      "metadata": {
        "id": "Rrz-rGjcizD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot( 2, 2, 1 )\n",
        "sns.lineplot( x='date', y='sales', data=df9, label='SALES' )\n",
        "sns.lineplot( x='date', y='predictions', data=df9, label='PREDICTIONS' )\n",
        "\n",
        "plt.subplot( 2, 2, 2 )\n",
        "sns.lineplot( x='date', y='error_rate', data=df9 )\n",
        "plt.axhline( 1, linestyle='--' )\n",
        "\n",
        "plt.subplot( 2, 2, 3 )\n",
        "sns.distplot( df9['error'] )\n",
        "\n",
        "plt.subplot( 2, 2, 4 )\n",
        "sns.scatterplot( df9['predictions'], df9['error'] )"
      ],
      "metadata": {
        "id": "1Us4P6gH0b-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.0. PASSO 10 - DEPLOY MODEL TO PRODUCTION"
      ],
      "metadata": {
        "id": "i_ciuWxqS8Fm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgMzPGeYf3iU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "da8b809c-0c5f-4f1f-ab4b-91cd50b23787"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fc37d8a5f5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving Trained Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel_xgb_tuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Rossmann_Store_Sales/Model trained/model_rossmann.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#from google.colab import files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#files.download('/content/model_rossmann.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_xgb_tuned' is not defined"
          ]
        }
      ],
      "source": [
        "# Saving Trained Model\n",
        "\n",
        "pickle.dump( model_xgb_tuned, open(\"/content/Rossmann_Store_Sales/Model trained/model_rossmann.pkl\", 'wb' ) )\n",
        "#from google.colab import files\n",
        "#files.download('/content/model_rossmann.pkl') "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1. Rossmann Class"
      ],
      "metadata": {
        "id": "yJE2gJnUTSrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import inflection\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "class Rossmann( object ):\n",
        "    def __init__( self ):\n",
        "        self.home_path='/content/Rossmann_Store_Sales/'\n",
        "        self.competition_distance_scaler      = pickle.load( open( self.home_path + 'Parameter/competition_distance_scaler.pkl', 'rb') )\n",
        "        self.promo_time_week_scaler           = pickle.load( open( self.home_path + 'Parameter/promo_time_week_scaler.pkl','rb') )\n",
        "        self.competition_time_month_scaler    = pickle.load( open( self.home_path + 'Parameter/competition_time_month_scaler.pkl','rb') )\n",
        "        self.year_scaler                      = pickle.load( open( self.home_path + 'Parameter/year_scaler.pkl','rb') )\n",
        "        self.store_type_scaler                = pickle.load( open( self.home_path + 'Parameter/store_type_scaler.pkl','rb') )\n",
        "          \n",
        "        \n",
        "\n",
        "    def data_cleaning( self, df1 ):\n",
        "\n",
        "        ## 1.1. Rename Columns\n",
        "\n",
        "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
        "                    'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
        "                    'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
        "\n",
        "        snakecase = lambda x: inflection.underscore( x )\n",
        "\n",
        "        cols_new = list( map( snakecase, cols_old ) )\n",
        "\n",
        "        # rename\n",
        "        df1.columns = cols_new\n",
        "\n",
        "        ## 1.3. Data Types\n",
        "        df1['date'] = pd.to_datetime( df1['date'] )\n",
        "\n",
        "        ## 1.5. Fillout NA\n",
        "        #competition_distance        \n",
        "        df1['competition_distance'] = df1['competition_distance'].apply( lambda x: 200000.0 if math.isnan( x ) else x )\n",
        "\n",
        "        #competition_open_since_month\n",
        "        df1['competition_open_since_month'] = df1.apply( lambda x: x['date'].month if math.isnan( x['competition_open_since_month'] ) else x['competition_open_since_month'], axis=1 )\n",
        "\n",
        "        #competition_open_since_year \n",
        "        df1['competition_open_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['competition_open_since_year'] ) else x['competition_open_since_year'], axis=1 )\n",
        "\n",
        "        #promo2_since_week           \n",
        "        df1['promo2_since_week'] = df1.apply( lambda x: x['date'].week if math.isnan( x['promo2_since_week'] ) else x['promo2_since_week'], axis=1 )\n",
        "\n",
        "        #promo2_since_year           \n",
        "        df1['promo2_since_year'] = df1.apply( lambda x: x['date'].year if math.isnan( x['promo2_since_year'] ) else x['promo2_since_year'], axis=1 )\n",
        "\n",
        "        #promo_interval              \n",
        "        month_map = {1: 'Jan',  2: 'Fev',  3: 'Mar',  4: 'Apr',  5: 'May',  6: 'Jun',  7: 'Jul',  8: 'Aug',  9: 'Sep',  10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
        "\n",
        "        df1['promo_interval'].fillna(0, inplace=True )\n",
        "\n",
        "        df1['month_map'] = df1['date'].dt.month.map( month_map )\n",
        "\n",
        "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply( lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split( ',' ) else 0, axis=1 )\n",
        "\n",
        "        ## 1.6. Change Data Types\n",
        "        # competiton\n",
        "        df1['competition_open_since_month'] = df1['competition_open_since_month'].astype( int )\n",
        "        df1['competition_open_since_year'] = df1['competition_open_since_year'].astype( int )\n",
        "            \n",
        "        # promo2\n",
        "        df1['promo2_since_week'] = df1['promo2_since_week'].astype( int )\n",
        "        df1['promo2_since_year'] = df1['promo2_since_year'].astype( int )\n",
        "\n",
        "        return df1\n",
        "    \n",
        "    \n",
        "    def feature_engineering( self, df2 ):\n",
        "\n",
        "        # year\n",
        "        df2['year'] = df2['date'].dt.year\n",
        "\n",
        "        # month\n",
        "        df2['month'] = df2['date'].dt.month\n",
        "\n",
        "        # day\n",
        "        df2['day'] = df2['date'].dt.day\n",
        "\n",
        "        # week of year\n",
        "        df2['week_of_year'] = df2['date'].dt.isocalendar().week \n",
        "\n",
        "        # year week\n",
        "        df2['year_week'] = df2['date'].dt.strftime( '%Y-%W' )\n",
        "\n",
        "        # competition since\n",
        "        df2['competition_since'] = df2.apply( lambda x: datetime.datetime( year=x['competition_open_since_year'], month=x['competition_open_since_month'],day=1 ), axis=1 )\n",
        "        df2['competition_time_month'] = ( ( df2['date'] - df2['competition_since'] )/30 ).apply( lambda x: x.days ).astype( int )\n",
        "\n",
        "        # promo since\n",
        "        df2['promo_since'] = df2['promo2_since_year'].astype( str ) + '-' + df2['promo2_since_week'].astype( str )\n",
        "        df2['promo_since'] = df2['promo_since'].apply( lambda x: datetime.datetime.strptime( x + '-1', '%Y-%W-%w' ) - datetime.timedelta( days=7 ) )\n",
        "        df2['promo_time_week'] = ( ( df2['date'] - df2['promo_since'] )/7 ).apply( lambda x: x.days ).astype( int )\n",
        "\n",
        "        # assortment\n",
        "        df2['assortment'] = df2['assortment'].apply( lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended' )\n",
        "\n",
        "        # state holiday\n",
        "        df2['state_holiday'] = df2['state_holiday'].apply( lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day' )\n",
        "        \n",
        "        # 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS\n",
        "        ## 3.1. Filtragem das Linhas\n",
        "        df2 = df2[(df2['open'] != 0)]\n",
        "\n",
        "        ## 3.2. Selecao das Colunas\n",
        "        cols_drop = [ 'open', 'promo_interval', 'month_map']\n",
        "        df2 = df2.drop( cols_drop, axis=1 )\n",
        "\n",
        "        return df2\n",
        "\n",
        "    def data_preparation( self, df5, ft ):\n",
        "        \n",
        "        ## 5.2. Rescaling ( Normalizando os ranges  )\n",
        "        # competition distance\n",
        "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform( df5[['competition_distance']].values )\n",
        "\n",
        "\n",
        "        # competition time month\n",
        "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform( df5[['competition_time_month']].values )\n",
        "        \n",
        "        # promo time week\n",
        "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform( df5[['promo_time_week']].values )\n",
        "\n",
        "        # year\n",
        "        df5['year'] = self.year_scaler.fit_transform( df5[['year']].values )\n",
        "\n",
        "        ### 5.3.1. Enconding\n",
        "        # state_holiday ( One Hot Enconding )\n",
        "        df5 = pd.get_dummies( df5, prefix=['state_holiday'], columns=['state_holiday'] )\n",
        "\n",
        "        # store_type ( Label Encoding )\n",
        "        df5['store_type'] = self.store_type_scaler.fit_transform( df5['store_type'] )\n",
        "\n",
        "\n",
        "        # assortment ( Ordinal Encoding )\n",
        "        assortment_dict = {'basic': 1, 'extra': 2, 'extended': 3}\n",
        "        df5['assortment'] = df5['assortment'].map( assortment_dict )\n",
        "\n",
        "        ### 5.3.3. Nature Transformation ( Natureza Cíclica )\n",
        "        # month\n",
        "        df5['month_sin'] = df5['month'].apply( lambda x: np.sin( x* ( 2. * np.pi/12 ) ) )\n",
        "        df5['month_cos'] = df5['month'].apply( lambda x: np.cos( x* ( 2. * np.pi/12 ) ) )\n",
        "\n",
        "        # day\n",
        "        df5['day_sin'] = df5['day'].apply( lambda x: np.sin( x* ( 2. * np.pi/30 ) ) )\n",
        "        df5['day_cos'] = df5['day'].apply( lambda x: np.cos( x* ( 2. * np.pi/30 ) ) )\n",
        "\n",
        "        # week of year\n",
        "        df5['week_of_year_sin'] = df5['week_of_year'].apply( lambda x: np.sin( x* ( 2. * np.pi/52 ) ) )\n",
        "        df5['week_of_year_cos'] = df5['week_of_year'].apply( lambda x: np.cos( x* ( 2. * np.pi/52 ) ) )\n",
        "\n",
        "        # day of week\n",
        "        df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x* ( 2. * np.pi/7 ) ) )\n",
        "        df5['day_of_week_cos'] = df5['day_of_week'].apply( lambda x: np.cos( x* ( 2. * np.pi/7 ) ) )\n",
        "\n",
        "        cols_selected = ['store', 'promo', 'store_type', 'assortment', 'competition_distance', 'competition_open_since_month', 'competition_open_since_year', 'promo2', 'promo2_since_week', \n",
        "                        'promo2_since_year', 'competition_time_month', 'promo_time_week', 'month_sin', 'month_cos', 'day_sin', 'day_cos', 'week_of_year_sin', 'week_of_year_cos', \n",
        "                        'day_of_week_sin', 'day_of_week_cos']\n",
        "\n",
        "        return df5[ cols_selected ]\n",
        "\n",
        "    def get_prediction( self, model, original_data, test_data ):\n",
        "\n",
        "        #prediction\n",
        "        pred = model.predict( test_data )\n",
        "\n",
        "        #join pred into the original data\n",
        "        original_data['prediction'] = np.expm1( pred )\n",
        "\n",
        "        return original_data.to_json( orient='records', date_format='iso' )      "
      ],
      "metadata": {
        "id": "10gRcqio0b40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2. API Handler "
      ],
      "metadata": {
        "id": "0WJnCTsGTXJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from flask import Flask, request, Response\n",
        "#from rossmann.Rossmann import Rossmann\n",
        "\n",
        "# loading model\n",
        "\n",
        "model = pickle.load( open( '/content/Rossmann_Store_Sales/Model trained/model_rossmann.pkl', 'rb') )\n",
        "\n",
        "# inicialize API\n",
        "app = Flask( __name__) \n",
        "            \n",
        "@app.route( '/rossmann/predict', methods=['POST'] )\n",
        "def rossmann_predict():\n",
        "    test_json = request.get_json()\n",
        "    \n",
        "    #Coleta de dados\n",
        "    if test_json: # there is data\n",
        "        if isinstance( test_json, dict ): # unique example / Unica linha\n",
        "            test_raw = pd.DataFrame( test_json, index=[0] )\n",
        "\n",
        "        else: # multiple example / Mais de uma linha\n",
        "            test_raw = pd.DataFrame( test_json, columns=test_json[0].keys() )\n",
        "\n",
        "        # Instantiate Rossmann class\n",
        "        pipeline = Rossmann()\n",
        "\n",
        "        # data cleaning\n",
        "        df1 = pipeline.data_cleaning( test_raw )\n",
        "\n",
        "        # feature enginerering\n",
        "        df2 = pipeline.feature_engineering( df1 )\n",
        "\n",
        "        # data preparation\n",
        "        df3 = pipeline.data_prediction( df2 )\n",
        "\n",
        "        # prediction\n",
        "        df_response = pipeline.get_prediction( model, test_raw, df3 )\n",
        "\n",
        "        return df_response\n",
        "\n",
        "    else:\n",
        "        return Response( '{}', status=200, mimetype='application/json' )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run( '0.0.0.0' )"
      ],
      "metadata": {
        "id": "ZiXPlpCy0b2P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3eb335f-6735-44a3-ab2b-c8eca80bf03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.3. API Tester"
      ],
      "metadata": {
        "id": "_ibg4bQSTc_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "JfrAXKwa5j1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading test dataset\n",
        "df10 = pd.read_csv( '/content/Rossmann_Store_Sales/Dataset/test.csv' )"
      ],
      "metadata": {
        "id": "BMh7oTua0bzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge test dataset + store\n",
        "df_test = pd.merge( df10, df_store_raw, how='left', on='Store' )"
      ],
      "metadata": {
        "id": "Zs7-4M1xLNSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kyfdmhubketn",
        "outputId": "213d1b64-ed02-4cfb-aef2-5d0282d15887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5418cae61a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_interactive_table_hint_button.py\u001b[0m in \u001b[0;36m_df_formatter_with_interactive_hint\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _output_callbacks[convert_func] = _output.register_callback(\n\u001b[1;32m    103\u001b[0m         convert_func, _convert_to_interactive)\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_get_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_interactive_table_hint_button.py\u001b[0m in \u001b[0;36m_get_html\u001b[0;34m(dataframe, key)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mcss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_HINT_BUTTON_CSS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mdata_table_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_data_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DATA_TABLE_HELP_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0mdf_html\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m       \u001b[0micon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_ICON_SVG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             )\n\u001b[0;32m-> 1047\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrameRenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self, buf, encoding, classes, notebook, border, table_id, render_links)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0mrender_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         )\n\u001b[0;32m-> 1029\u001b[0;31m         \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msave_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</div>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_show_dimensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_table\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</table>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_body\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_hierarchical_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_regular_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</tbody>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_regular_rows\u001b[0;34m(self, fmt_values, indent)\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_col_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             self.write_tr(\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnindex_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             )\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mwrite_tr\u001b[0;34m(self, line, indent, indent_delta, header, align, tags, nindex_levels)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_th\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mindent\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mindent_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36mwrite_td\u001b[0;34m(self, s, indent, tags)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_td\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"td\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     def _write_cell(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/html.py\u001b[0m in \u001b[0;36m_write_cell\u001b[0;34m(self, s, kind, indent, tags)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mend_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{start_tag}{rs}{end_a}</{kind}>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     def write_tr(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose store for prediction\n",
        "df_test = df_test[df_test['Store'] == 22]\n",
        "\n",
        "#remove closed days\n",
        "#df_test = df_test[df_test['Open_y'] != 0]\n",
        "#df_test = df_test[~df_test['Open'].isnull()]\n",
        "#df_test = df_test.drop( 'Id',axis=1 )\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "zYWKjw4Gkdss",
        "outputId": "1f0fc637-0c86-46ca-966c-1264017a146d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Id_x  Store  DayOfWeek_x      Date_x  Open_x  Promo_x StateHoliday_x  SchoolHoliday_x  Id_y  DayOfWeek_y      Date_y  Open_y  Promo_y StateHoliday_y  SchoolHoliday_y\n",
              "720    16     22            4  2015-09-17     1.0        1              0                0    16            4  2015-09-17     1.0        1              0                0\n",
              "721    16     22            4  2015-09-17     1.0        1              0                0   872            3  2015-09-16     1.0        1              0                0\n",
              "722    16     22            4  2015-09-17     1.0        1              0                0  1728            2  2015-09-15     1.0        1              0                0\n",
              "723    16     22            4  2015-09-17     1.0        1              0                0  2584            1  2015-09-14     1.0        1              0                1\n",
              "724    16     22            4  2015-09-17     1.0        1              0                0  3440            7  2015-09-13     0.0        0              0                0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-839afde0-ce8c-4583-82db-dbd6202e6be5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id_x</th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek_x</th>\n",
              "      <th>Date_x</th>\n",
              "      <th>Open_x</th>\n",
              "      <th>Promo_x</th>\n",
              "      <th>StateHoliday_x</th>\n",
              "      <th>SchoolHoliday_x</th>\n",
              "      <th>Id_y</th>\n",
              "      <th>DayOfWeek_y</th>\n",
              "      <th>Date_y</th>\n",
              "      <th>Open_y</th>\n",
              "      <th>Promo_y</th>\n",
              "      <th>StateHoliday_y</th>\n",
              "      <th>SchoolHoliday_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>872</td>\n",
              "      <td>3</td>\n",
              "      <td>2015-09-16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1728</td>\n",
              "      <td>2</td>\n",
              "      <td>2015-09-15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2584</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-09-14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-09-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3440</td>\n",
              "      <td>7</td>\n",
              "      <td>2015-09-13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-839afde0-ce8c-4583-82db-dbd6202e6be5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-839afde0-ce8c-4583-82db-dbd6202e6be5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-839afde0-ce8c-4583-82db-dbd6202e6be5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Dataframe to json\n",
        "data = json.dumps( df_test.to_dict( orient='records') )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "F8StNdjwMz4P",
        "outputId": "7932fb8e-5c91-4ae1-de65-3bff87330ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6f1d44fbc519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert Dataframe to json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API Call\n",
        "url = 'http://0.0.0.0:5000/rossmann/predict' # É o endpoint, onde será enviado\n",
        "header = {'Content-type': 'application/json' }  # Indica o tipo de dado que está recebendo\n",
        "data = data\n",
        "\n",
        "r = requests.post( url=url, data=data, headers=header )\n",
        "print( 'Status Code {}'.format( r.status_code ) )"
      ],
      "metadata": {
        "id": "emnPTgAtMz1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.DataFrame( r.json(), columns=r.json()[0].keys() )"
      ],
      "metadata": {
        "id": "PYDrntahMzyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2 = d1[['store', 'prediction']].groupby( 'store' ).sum().reset_index()\n",
        "\n",
        "for i in range( len( d2 ) ):\n",
        "    print( 'Store Number {} will sell R${:,.2f} in the next 6 weeks'.format(\n",
        "        d2.loc[i, 'store'],\n",
        "        d2.loc[i, 'prediction'] ) )"
      ],
      "metadata": {
        "id": "LcTS3GLsMzwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kOSmZKBMxni-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Cme0l2fgyTFh",
        "mAFJ7tGZyTFn",
        "XEPkhdtxyTFo",
        "gU_NLcbfyTFo",
        "WFO6TERpyTFp",
        "ZQVDL2bzyTFp",
        "PVc5kcYLyTFq",
        "Q2jyu4OryTFr",
        "sS8hzOB4yTFu",
        "KO2hs5lcyTFu",
        "niSe3joDyTFu",
        "DUeCXTpyyTFv",
        "VRiWMOiSyTFw",
        "4DtHBNRayTFw",
        "cVgxFl_oml9b",
        "m4XkvK0TtN6y",
        "TMdKWQI_tgFv",
        "WIIAH779s09U",
        "MqHndotYAGNi",
        "G3utuDePAGKc",
        "H1Sqpjqknpz-",
        "NHR4BxhwszJZ",
        "B-cSDG6wt02R",
        "4BS4fErVt_mO",
        "XoBuvjNi_t0_",
        "IvKvzhu8CeAC",
        "3bvJiBgiCd9M",
        "agpnBKG-YY0l",
        "_m_ucl1t3ncQ",
        "gJQ4NRCF8oJu",
        "y9cSWGlMdvMZ",
        "f6UAKnOlq_do",
        "7ooXreuhUdQt",
        "yHqRjzSbUnGv",
        "bjw9QbM9UrnN",
        "epUmwLzMtGIg",
        "ixnopyV9uQFg",
        "-J95fe9-7y9S",
        "FKVO7wRBhIQ_",
        "ZOqFh1Bh83Nu",
        "MWQ6OeleiIGk",
        "KH95WOaTU6hu",
        "y99H_AUAip9t",
        "l53P6u6ZDKUm",
        "L2W5uJzrf7rX",
        "yjQAZPoFgEf3",
        "lauhv_lWiWTD",
        "iYbOmkZHilU0",
        "wKoboWOLipaw",
        "lxvl9H17iuMN"
      ],
      "name": "Rossmann_Store_Sales_Modulo_10_Deploy_Model_to_Production.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}